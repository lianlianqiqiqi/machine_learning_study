{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('../F_MNIST_data', download=False, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('../F_MNIST_data', download=False, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        layers = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layers])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.dropout = nn.Dropout(p = drop_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(784, 10, [516, 256], drop_p=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    model.eval()   #shut off dropout\n",
    "    current_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in iter(testloader):\n",
    "        images.resize_(images.size()[0], 28 * 28)\n",
    "        with torch.no_grad():\n",
    "            output = model.forward(images)\n",
    "            current_loss += criterion(output, labels).item()\n",
    "        \n",
    "            ps = torch.exp(output).data\n",
    "            equality = (labels.data == ps.max(dim=1)[1])\n",
    "            accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "        \n",
    "    return current_loss / len(testloader), accuracy / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangtianhao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n",
      "/Users/huangtianhao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3 epoch\n",
      "train loss: 51.2747\n",
      "test accuracy: 0.7260\n",
      "test loss: 0.7617\n",
      "1 / 3 epoch\n",
      "train loss: 25.6599\n",
      "test accuracy: 0.7496\n",
      "test loss: 0.6407\n",
      "1 / 3 epoch\n",
      "train loss: 22.9906\n",
      "test accuracy: 0.7789\n",
      "test loss: 0.5924\n",
      "1 / 3 epoch\n",
      "train loss: 21.9442\n",
      "test accuracy: 0.7927\n",
      "test loss: 0.5696\n",
      "1 / 3 epoch\n",
      "train loss: 21.9545\n",
      "test accuracy: 0.8038\n",
      "test loss: 0.5305\n",
      "1 / 3 epoch\n",
      "train loss: 20.0623\n",
      "test accuracy: 0.8024\n",
      "test loss: 0.5400\n",
      "1 / 3 epoch\n",
      "train loss: 19.5730\n",
      "test accuracy: 0.8170\n",
      "test loss: 0.4989\n",
      "1 / 3 epoch\n",
      "train loss: 20.1864\n",
      "test accuracy: 0.8174\n",
      "test loss: 0.5015\n",
      "1 / 3 epoch\n",
      "train loss: 19.0593\n",
      "test accuracy: 0.8200\n",
      "test loss: 0.4837\n",
      "1 / 3 epoch\n",
      "train loss: 17.4100\n",
      "test accuracy: 0.8252\n",
      "test loss: 0.4717\n",
      "1 / 3 epoch\n",
      "train loss: 16.9842\n",
      "test accuracy: 0.8264\n",
      "test loss: 0.4703\n",
      "1 / 3 epoch\n",
      "train loss: 17.6623\n",
      "test accuracy: 0.8394\n",
      "test loss: 0.4476\n",
      "1 / 3 epoch\n",
      "train loss: 18.8782\n",
      "test accuracy: 0.8412\n",
      "test loss: 0.4463\n",
      "1 / 3 epoch\n",
      "train loss: 17.7012\n",
      "test accuracy: 0.8356\n",
      "test loss: 0.4469\n",
      "1 / 3 epoch\n",
      "train loss: 17.3067\n",
      "test accuracy: 0.8376\n",
      "test loss: 0.4355\n",
      "1 / 3 epoch\n",
      "train loss: 16.6106\n",
      "test accuracy: 0.8348\n",
      "test loss: 0.4556\n",
      "1 / 3 epoch\n",
      "train loss: 17.3171\n",
      "test accuracy: 0.8372\n",
      "test loss: 0.4465\n",
      "1 / 3 epoch\n",
      "train loss: 16.7567\n",
      "test accuracy: 0.8426\n",
      "test loss: 0.4239\n",
      "1 / 3 epoch\n",
      "train loss: 16.4825\n",
      "test accuracy: 0.8444\n",
      "test loss: 0.4241\n",
      "1 / 3 epoch\n",
      "train loss: 16.3242\n",
      "test accuracy: 0.8520\n",
      "test loss: 0.4015\n",
      "1 / 3 epoch\n",
      "train loss: 16.7702\n",
      "test accuracy: 0.8480\n",
      "test loss: 0.4107\n",
      "1 / 3 epoch\n",
      "train loss: 16.5566\n",
      "test accuracy: 0.8362\n",
      "test loss: 0.4473\n",
      "1 / 3 epoch\n",
      "train loss: 14.8090\n",
      "test accuracy: 0.8438\n",
      "test loss: 0.4329\n",
      "2 / 3 epoch\n",
      "train loss: 17.5399\n",
      "test accuracy: 0.8213\n",
      "test loss: 0.4949\n",
      "2 / 3 epoch\n",
      "train loss: 15.4619\n",
      "test accuracy: 0.8495\n",
      "test loss: 0.4147\n",
      "2 / 3 epoch\n",
      "train loss: 15.5453\n",
      "test accuracy: 0.8599\n",
      "test loss: 0.3963\n",
      "2 / 3 epoch\n",
      "train loss: 15.3614\n",
      "test accuracy: 0.8181\n",
      "test loss: 0.4827\n",
      "2 / 3 epoch\n",
      "train loss: 14.4478\n",
      "test accuracy: 0.8522\n",
      "test loss: 0.4026\n",
      "2 / 3 epoch\n",
      "train loss: 14.2053\n",
      "test accuracy: 0.8453\n",
      "test loss: 0.4247\n",
      "2 / 3 epoch\n",
      "train loss: 15.2157\n",
      "test accuracy: 0.8535\n",
      "test loss: 0.4078\n",
      "2 / 3 epoch\n",
      "train loss: 15.3515\n",
      "test accuracy: 0.8504\n",
      "test loss: 0.4023\n",
      "2 / 3 epoch\n",
      "train loss: 14.8168\n",
      "test accuracy: 0.8545\n",
      "test loss: 0.4090\n",
      "2 / 3 epoch\n",
      "train loss: 15.3018\n",
      "test accuracy: 0.8444\n",
      "test loss: 0.4277\n",
      "2 / 3 epoch\n",
      "train loss: 14.8555\n",
      "test accuracy: 0.8428\n",
      "test loss: 0.4134\n",
      "2 / 3 epoch\n",
      "train loss: 14.5479\n",
      "test accuracy: 0.8464\n",
      "test loss: 0.4106\n",
      "2 / 3 epoch\n",
      "train loss: 15.2873\n",
      "test accuracy: 0.8607\n",
      "test loss: 0.3770\n",
      "2 / 3 epoch\n",
      "train loss: 14.1628\n",
      "test accuracy: 0.8630\n",
      "test loss: 0.3797\n",
      "2 / 3 epoch\n",
      "train loss: 14.2360\n",
      "test accuracy: 0.8573\n",
      "test loss: 0.3930\n",
      "2 / 3 epoch\n",
      "train loss: 13.8166\n",
      "test accuracy: 0.8592\n",
      "test loss: 0.3825\n",
      "2 / 3 epoch\n",
      "train loss: 14.3670\n",
      "test accuracy: 0.8543\n",
      "test loss: 0.3887\n",
      "2 / 3 epoch\n",
      "train loss: 14.4055\n",
      "test accuracy: 0.8513\n",
      "test loss: 0.4143\n",
      "2 / 3 epoch\n",
      "train loss: 13.8049\n",
      "test accuracy: 0.8586\n",
      "test loss: 0.3866\n",
      "2 / 3 epoch\n",
      "train loss: 14.4614\n",
      "test accuracy: 0.8537\n",
      "test loss: 0.4044\n",
      "2 / 3 epoch\n",
      "train loss: 14.2899\n",
      "test accuracy: 0.8562\n",
      "test loss: 0.3892\n",
      "2 / 3 epoch\n",
      "train loss: 13.6681\n",
      "test accuracy: 0.8634\n",
      "test loss: 0.3866\n",
      "2 / 3 epoch\n",
      "train loss: 14.0166\n",
      "test accuracy: 0.8670\n",
      "test loss: 0.3651\n",
      "3 / 3 epoch\n",
      "train loss: 14.3321\n",
      "test accuracy: 0.8545\n",
      "test loss: 0.3884\n",
      "3 / 3 epoch\n",
      "train loss: 14.1841\n",
      "test accuracy: 0.8572\n",
      "test loss: 0.4037\n",
      "3 / 3 epoch\n",
      "train loss: 12.5149\n",
      "test accuracy: 0.8692\n",
      "test loss: 0.3729\n",
      "3 / 3 epoch\n",
      "train loss: 13.5098\n",
      "test accuracy: 0.8604\n",
      "test loss: 0.3864\n",
      "3 / 3 epoch\n",
      "train loss: 13.3559\n",
      "test accuracy: 0.8555\n",
      "test loss: 0.3841\n",
      "3 / 3 epoch\n",
      "train loss: 13.4532\n",
      "test accuracy: 0.8611\n",
      "test loss: 0.3856\n",
      "3 / 3 epoch\n",
      "train loss: 12.7692\n",
      "test accuracy: 0.8633\n",
      "test loss: 0.3767\n",
      "3 / 3 epoch\n",
      "train loss: 13.7029\n",
      "test accuracy: 0.8615\n",
      "test loss: 0.3751\n",
      "3 / 3 epoch\n",
      "train loss: 13.3264\n",
      "test accuracy: 0.8640\n",
      "test loss: 0.3698\n",
      "3 / 3 epoch\n",
      "train loss: 14.3140\n",
      "test accuracy: 0.8702\n",
      "test loss: 0.3639\n",
      "3 / 3 epoch\n",
      "train loss: 12.6948\n",
      "test accuracy: 0.8643\n",
      "test loss: 0.3765\n",
      "3 / 3 epoch\n",
      "train loss: 13.3346\n",
      "test accuracy: 0.8631\n",
      "test loss: 0.3851\n",
      "3 / 3 epoch\n",
      "train loss: 12.6376\n",
      "test accuracy: 0.8623\n",
      "test loss: 0.3721\n",
      "3 / 3 epoch\n",
      "train loss: 13.1746\n",
      "test accuracy: 0.8644\n",
      "test loss: 0.3754\n",
      "3 / 3 epoch\n",
      "train loss: 12.7549\n",
      "test accuracy: 0.8672\n",
      "test loss: 0.3635\n",
      "3 / 3 epoch\n",
      "train loss: 12.7297\n",
      "test accuracy: 0.8648\n",
      "test loss: 0.3644\n",
      "3 / 3 epoch\n",
      "train loss: 13.7645\n",
      "test accuracy: 0.8706\n",
      "test loss: 0.3639\n",
      "3 / 3 epoch\n",
      "train loss: 12.6684\n",
      "test accuracy: 0.8689\n",
      "test loss: 0.3658\n",
      "3 / 3 epoch\n",
      "train loss: 12.4360\n",
      "test accuracy: 0.8660\n",
      "test loss: 0.3776\n",
      "3 / 3 epoch\n",
      "train loss: 12.8261\n",
      "test accuracy: 0.8717\n",
      "test loss: 0.3561\n",
      "3 / 3 epoch\n",
      "train loss: 12.5075\n",
      "test accuracy: 0.8695\n",
      "test loss: 0.3651\n",
      "3 / 3 epoch\n",
      "train loss: 12.5829\n",
      "test accuracy: 0.8667\n",
      "test loss: 0.3731\n",
      "3 / 3 epoch\n",
      "train loss: 12.4632\n",
      "test accuracy: 0.8674\n",
      "test loss: 0.3764\n",
      "3 / 3 epoch\n",
      "train loss: 13.2254\n",
      "test accuracy: 0.8692\n",
      "test loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        images.resize_(images.size()[0], 28 * 28)\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss, test_accuracy = validation(model, testloader, criterion)\n",
    "            print('{} / {} epoch'.format(e + 1,  epochs))\n",
    "            print('train loss: {:.4f}'.format(running_loss) )\n",
    "            print('test accuracy: {:.4f}'.format(test_accuracy))\n",
    "            print('test loss: {:.4f}'.format(test_loss))\n",
    "            running_loss = 0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4548e-01, 4.2609e-03, 6.3051e-01, 1.0959e-03, 3.7725e-02, 5.3306e-05,\n",
      "         1.7283e-01, 2.1140e-05, 7.9712e-03, 5.1721e-05],\n",
      "        [4.7446e-09, 5.9910e-08, 1.0358e-09, 3.3874e-10, 1.1260e-09, 1.2740e-04,\n",
      "         1.6643e-07, 4.1647e-03, 2.2085e-08, 9.9571e-01],\n",
      "        [1.0520e-04, 4.1210e-06, 1.5109e-05, 3.9734e-06, 6.8906e-06, 9.6700e-01,\n",
      "         6.0272e-05, 9.3154e-03, 1.6341e-05, 2.3475e-02],\n",
      "        [2.0261e-03, 2.2963e-03, 9.4340e-05, 9.9484e-01, 1.6431e-05, 3.9934e-06,\n",
      "         6.9908e-04, 9.5077e-10, 2.8019e-05, 1.0260e-07],\n",
      "        [1.5607e-04, 1.6646e-06, 9.8449e-01, 1.9591e-05, 8.0521e-03, 3.4986e-08,\n",
      "         7.2753e-03, 9.9981e-10, 4.1116e-06, 3.1020e-08],\n",
      "        [4.1217e-01, 4.2536e-05, 9.4651e-04, 2.5904e-04, 2.9504e-05, 2.8575e-06,\n",
      "         5.8583e-01, 1.5808e-07, 7.2574e-04, 6.4538e-07],\n",
      "        [8.0593e-06, 7.1827e-08, 5.2240e-06, 2.4458e-07, 6.5340e-06, 9.9883e-01,\n",
      "         1.0263e-05, 1.1143e-03, 3.1789e-06, 2.0957e-05],\n",
      "        [1.6945e-11, 1.0000e+00, 9.6189e-12, 6.5910e-11, 8.6932e-11, 5.3369e-17,\n",
      "         1.5958e-10, 8.1082e-18, 3.5324e-15, 1.2095e-15],\n",
      "        [6.3898e-05, 3.4928e-06, 8.6134e-06, 3.0660e-06, 8.4737e-06, 9.9386e-01,\n",
      "         3.9918e-05, 3.2483e-03, 5.8411e-05, 2.7070e-03],\n",
      "        [6.9587e-05, 5.3095e-08, 1.9291e-05, 3.4286e-06, 7.6850e-06, 5.4565e-07,\n",
      "         1.3521e-03, 5.5544e-05, 9.9847e-01, 1.6935e-05],\n",
      "        [2.1243e-03, 5.1601e-05, 8.9920e-01, 8.3209e-05, 2.6316e-02, 4.0465e-06,\n",
      "         7.2159e-02, 5.6521e-07, 5.3959e-05, 5.3817e-06],\n",
      "        [3.1260e-04, 2.8999e-06, 2.7008e-02, 6.1021e-05, 1.5708e-01, 5.4844e-07,\n",
      "         8.1552e-01, 1.3168e-07, 1.4631e-05, 6.6270e-07],\n",
      "        [1.9800e-02, 2.0337e-07, 1.4758e-04, 3.3541e-06, 1.2075e-04, 1.0354e-03,\n",
      "         1.5441e-03, 6.0881e-06, 9.7733e-01, 1.5691e-05],\n",
      "        [5.8870e-01, 3.7594e-04, 7.8110e-04, 1.7663e-02, 2.4190e-04, 2.6106e-05,\n",
      "         3.9165e-01, 5.1982e-07, 5.6656e-04, 3.0761e-06],\n",
      "        [1.4449e-09, 1.0000e+00, 4.5958e-09, 2.1745e-07, 7.5784e-09, 6.4526e-12,\n",
      "         2.0187e-08, 1.6862e-13, 2.1503e-11, 5.7700e-12],\n",
      "        [2.1849e-04, 2.2066e-06, 9.8684e-01, 2.5892e-05, 5.9034e-03, 3.2791e-07,\n",
      "         6.9910e-03, 1.7497e-08, 1.7871e-05, 3.0137e-07],\n",
      "        [1.5506e-09, 1.0000e+00, 8.1629e-10, 2.0969e-08, 5.1112e-09, 3.0719e-13,\n",
      "         1.2432e-08, 3.9022e-14, 4.8948e-12, 2.4741e-12],\n",
      "        [6.1641e-01, 1.1799e-03, 6.1491e-04, 8.7171e-02, 6.4839e-05, 1.2745e-05,\n",
      "         2.9444e-01, 1.1271e-07, 1.0824e-04, 1.2884e-06],\n",
      "        [5.6788e-01, 1.6417e-02, 1.8171e-03, 1.0189e-01, 3.9487e-04, 7.5297e-05,\n",
      "         3.1109e-01, 1.7388e-06, 4.2649e-04, 1.1037e-05],\n",
      "        [1.0771e-03, 4.4525e-06, 1.9886e-01, 1.4552e-04, 3.2768e-01, 2.0832e-05,\n",
      "         4.7210e-01, 4.6565e-07, 1.0870e-04, 2.5660e-06],\n",
      "        [1.0810e-09, 1.0000e+00, 9.5729e-11, 7.1696e-09, 2.0320e-09, 2.2879e-13,\n",
      "         1.6994e-08, 6.5247e-14, 2.5385e-12, 2.5951e-12],\n",
      "        [7.2862e-06, 3.6882e-09, 1.3294e-08, 3.5676e-09, 1.3744e-08, 9.9872e-01,\n",
      "         1.4648e-07, 3.1917e-04, 9.3430e-04, 1.8776e-05],\n",
      "        [1.1519e-06, 8.1465e-07, 4.8673e-07, 5.4885e-07, 1.6009e-06, 2.1958e-02,\n",
      "         1.2476e-06, 9.7757e-01, 1.3129e-04, 3.3084e-04],\n",
      "        [2.2882e-04, 4.5458e-07, 9.8073e-01, 8.8174e-06, 1.9375e-03, 1.3108e-07,\n",
      "         1.7069e-02, 7.1202e-09, 2.2117e-05, 1.1864e-07],\n",
      "        [4.1591e-03, 1.8903e-03, 3.1392e-02, 2.3450e-01, 6.8065e-01, 7.6819e-05,\n",
      "         4.3684e-02, 2.2984e-05, 3.6045e-03, 1.7956e-05],\n",
      "        [5.4464e-06, 2.2126e-08, 7.7672e-06, 3.4158e-07, 9.5858e-06, 9.9892e-01,\n",
      "         1.0777e-05, 1.0186e-03, 2.1592e-05, 1.2646e-06],\n",
      "        [1.0290e-02, 9.6569e-04, 5.7406e-03, 9.1108e-03, 1.3948e-02, 5.7777e-02,\n",
      "         1.6524e-02, 2.4632e-02, 8.5998e-01, 1.0328e-03],\n",
      "        [3.6597e-06, 9.9994e-01, 9.7089e-07, 4.2792e-05, 3.3825e-06, 1.4564e-09,\n",
      "         7.6428e-06, 2.7972e-10, 3.8826e-08, 5.9184e-09],\n",
      "        [2.0740e-03, 1.7206e-05, 1.1915e-01, 7.5454e-04, 1.2284e-01, 1.6530e-05,\n",
      "         7.5491e-01, 3.9978e-06, 2.1827e-04, 1.0820e-05],\n",
      "        [8.5801e-05, 1.5942e-06, 5.9189e-06, 2.1993e-06, 4.7174e-06, 8.5481e-05,\n",
      "         3.5709e-04, 7.4791e-06, 9.9944e-01, 6.2364e-06],\n",
      "        [5.6487e-03, 7.9025e-05, 3.3526e-01, 2.8866e-03, 1.6504e-01, 2.2223e-04,\n",
      "         4.8997e-01, 3.4881e-05, 7.9138e-04, 6.1709e-05],\n",
      "        [3.5388e-05, 8.2442e-07, 6.6202e-06, 2.1965e-06, 1.4653e-05, 9.9276e-01,\n",
      "         3.7299e-05, 6.9192e-03, 4.7709e-05, 1.7246e-04],\n",
      "        [1.1333e-03, 5.9628e-05, 4.3890e-02, 3.3053e-02, 7.8320e-01, 8.1379e-06,\n",
      "         1.3835e-01, 2.7575e-06, 2.9987e-04, 2.4991e-06],\n",
      "        [2.0807e-01, 5.7154e-04, 5.1155e-04, 3.4894e-03, 2.8436e-04, 3.7151e-06,\n",
      "         7.8703e-01, 1.8962e-07, 4.4322e-05, 7.0691e-07],\n",
      "        [2.5445e-05, 4.6337e-08, 3.2724e-07, 2.1651e-07, 3.9917e-07, 2.7307e-03,\n",
      "         3.7245e-05, 5.6493e-06, 9.9720e-01, 3.3037e-07],\n",
      "        [2.0455e-07, 1.2369e-06, 5.6704e-08, 2.3693e-08, 2.7497e-07, 2.6679e-04,\n",
      "         5.6171e-06, 5.4649e-02, 1.1284e-06, 9.4508e-01],\n",
      "        [8.5138e-01, 2.1532e-02, 5.6699e-04, 3.2810e-02, 1.2239e-04, 2.7909e-06,\n",
      "         9.3532e-02, 2.4165e-08, 5.7579e-05, 2.2161e-07],\n",
      "        [1.9325e-05, 2.8807e-05, 2.3700e-05, 1.1200e-05, 1.1406e-04, 8.2766e-03,\n",
      "         6.2357e-05, 9.0439e-01, 4.2635e-04, 8.6652e-02],\n",
      "        [4.5338e-09, 1.0000e+00, 2.9092e-10, 1.1586e-08, 4.0470e-09, 1.0445e-12,\n",
      "         7.1336e-08, 1.1263e-13, 1.1251e-11, 4.8078e-12],\n",
      "        [3.7952e-05, 1.5359e-04, 2.6196e-05, 1.7437e-05, 5.3836e-05, 3.5802e-03,\n",
      "         4.4431e-04, 1.9381e-01, 3.3784e-04, 8.0154e-01],\n",
      "        [2.9334e-04, 7.7292e-06, 1.1222e-02, 1.5108e-04, 2.4892e-01, 8.8034e-07,\n",
      "         7.3940e-01, 1.0996e-07, 5.3797e-06, 5.3403e-07],\n",
      "        [3.1746e-01, 3.9116e-04, 5.2371e-04, 1.1224e-02, 8.0621e-05, 7.3774e-06,\n",
      "         6.7019e-01, 1.1310e-07, 1.2057e-04, 6.3192e-07],\n",
      "        [3.1136e-10, 1.0000e+00, 1.9781e-10, 7.8105e-09, 5.0746e-09, 5.2851e-13,\n",
      "         6.5131e-09, 2.2717e-13, 4.1749e-12, 4.6406e-12],\n",
      "        [5.8809e-03, 9.6061e-03, 3.5058e-03, 9.6873e-01, 3.3726e-03, 8.1686e-05,\n",
      "         7.3732e-03, 1.1448e-06, 1.4430e-03, 9.3278e-06],\n",
      "        [7.7173e-01, 2.7335e-06, 1.8735e-05, 2.3535e-04, 8.9646e-08, 1.2721e-07,\n",
      "         2.2800e-01, 6.3436e-10, 7.5748e-06, 3.9625e-09],\n",
      "        [2.4247e-01, 6.4239e-04, 2.0356e-01, 1.6385e-02, 4.4260e-03, 1.5032e-04,\n",
      "         5.2425e-01, 3.2159e-05, 8.0177e-03, 6.0926e-05],\n",
      "        [5.9108e-04, 2.8388e-07, 1.7436e-03, 7.7024e-05, 9.0999e-03, 1.3544e-08,\n",
      "         9.8849e-01, 3.6314e-10, 1.5604e-06, 6.4096e-09],\n",
      "        [2.4656e-05, 3.4835e-08, 7.4094e-07, 2.4383e-07, 1.9091e-07, 2.1395e-04,\n",
      "         7.0337e-05, 4.4697e-06, 9.9969e-01, 4.0265e-07],\n",
      "        [3.8581e-03, 4.2203e-04, 9.3636e-01, 1.7425e-04, 1.9535e-02, 2.9773e-06,\n",
      "         3.9560e-02, 5.0870e-07, 8.3966e-05, 1.8452e-06],\n",
      "        [5.9560e-01, 1.8037e-03, 3.4150e-03, 5.2634e-02, 1.4310e-03, 1.0493e-04,\n",
      "         3.4376e-01, 4.2920e-06, 1.2325e-03, 1.2523e-05],\n",
      "        [6.7358e-01, 1.3944e-04, 9.0738e-04, 6.2249e-02, 5.0408e-05, 1.9146e-06,\n",
      "         2.6300e-01, 7.4105e-09, 7.2681e-05, 1.1993e-07],\n",
      "        [4.8752e-07, 9.9999e-01, 2.8202e-08, 6.1032e-06, 2.3964e-07, 1.9207e-10,\n",
      "         1.1481e-06, 7.6577e-12, 1.4159e-09, 3.4036e-10],\n",
      "        [7.2644e-03, 7.4074e-04, 9.2892e-01, 7.5485e-03, 1.7878e-02, 1.6633e-05,\n",
      "         3.6187e-02, 3.3755e-07, 1.4363e-03, 8.5435e-06],\n",
      "        [3.7839e-08, 9.3376e-08, 3.5891e-08, 2.6995e-08, 3.5438e-07, 2.7783e-03,\n",
      "         1.1657e-07, 9.9693e-01, 3.0139e-06, 2.8302e-04],\n",
      "        [8.3508e-08, 3.2204e-07, 1.0864e-07, 6.7785e-08, 8.9910e-07, 2.0458e-03,\n",
      "         3.8945e-07, 9.9666e-01, 3.5133e-06, 1.2857e-03],\n",
      "        [2.7061e-08, 2.4227e-08, 3.4297e-08, 3.9431e-08, 6.6552e-07, 1.2148e-03,\n",
      "         1.1388e-07, 9.9876e-01, 3.9231e-06, 2.3309e-05],\n",
      "        [8.2777e-04, 5.8583e-05, 9.5731e-02, 2.6941e-05, 7.7084e-01, 4.1601e-06,\n",
      "         1.3250e-01, 2.0924e-07, 8.5415e-06, 1.7397e-06],\n",
      "        [5.1913e-04, 1.9337e-04, 3.1064e-05, 9.9868e-01, 8.0473e-06, 8.9008e-07,\n",
      "         5.5986e-04, 2.5151e-10, 7.0060e-06, 2.8316e-08],\n",
      "        [5.0939e-08, 3.9245e-08, 5.5899e-08, 6.1134e-08, 7.9078e-07, 1.5379e-03,\n",
      "         2.1629e-07, 9.9836e-01, 9.1145e-06, 8.7586e-05],\n",
      "        [9.7092e-01, 6.5315e-06, 1.6309e-04, 5.2083e-04, 4.5191e-07, 1.6154e-07,\n",
      "         2.8370e-02, 1.8675e-10, 1.6112e-05, 2.9809e-09],\n",
      "        [2.3199e-01, 1.7754e-03, 6.5794e-02, 1.7088e-01, 1.0730e-01, 5.1165e-04,\n",
      "         4.0814e-01, 1.2394e-04, 1.3398e-02, 9.0635e-05],\n",
      "        [2.3954e-02, 1.2985e-03, 8.8082e-02, 4.6001e-03, 5.9380e-01, 7.4472e-04,\n",
      "         2.1919e-01, 2.1879e-04, 6.7629e-02, 4.7520e-04],\n",
      "        [2.8543e-02, 2.1852e-04, 9.4119e-01, 4.4257e-05, 1.4161e-02, 8.3565e-07,\n",
      "         1.5707e-02, 2.8334e-07, 1.3806e-04, 5.3352e-07],\n",
      "        [1.3240e-07, 2.1231e-10, 1.1912e-07, 1.6717e-09, 6.6657e-08, 9.9997e-01,\n",
      "         2.0648e-07, 2.7302e-05, 2.0509e-07, 4.3245e-08]])\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels = next(iter(testloader))\n",
    "\n",
    "model.eval()\n",
    "test_images.resize_(test_images.size()[0], 28 * 28)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.forward(test_images)\n",
    "    ps = torch.exp(output)\n",
    "    print(ps.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
